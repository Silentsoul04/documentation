# CLOUD COMPUTE SECURITY

#### CLOUD COMPUTE SECURITY

Cloud provides resources abstracted from physical hardware via one or more layers of virtualization. The **compute** component provides process and system memory (RAM) resource as required for a particular workload. The workload could be a virtual machine instance configured with four CPUs and 16 GB RAM or it could be a container instance spun up to perform a function and return a result within a given timeframe. The virtualization layer ensures that the resources required for this task are made available on-demand. This can be referred to as dynamic resource allocation. It will be the responsibility of the CSP to ensure this capability is met to the standards agreed in the SLA.

Within the compute component, the following critical security considerations can be identified.

**Container Security**  
A container uses many shared components on the underlying platform, meaning it must be carefully configured to reduce the risk of data exposure. In a container engine such as Docker, each container is isolated from others through separate namespaces and control groups (docs.docker.com/engine/security/security). Namespaces prevent one container reading or writing processes in another, while control groups ensure that one container cannot overwhelm others in a DoS-type attack.

**API Inspection and Integration**  
The API is the means by which consumers interact with the cloud infrastructure, platform, or application. The consumer may use direct API calls, or may use a CSP-supplied web console as a graphical interface for the API. Monitoring API usage gives warning if the system is becoming overloaded (ensuring availability) and allows detection of unauthorized usage or attempted usage.

  
-   Number of requests—this basic load metric counts number of requests per second or requests per minute. Depending on the service type, you might be able to establish baselines for typical usage and set thresholds for alerting abnormal usage. An unexplained spike in API calls could be an indicator of a DDoS attack, for instance.
  
-   Latency—this is the time in milliseconds (ms) taken for the service to respond to an API call. This can be measured for specific services or as an aggregate value across all services. High latency usually means that compute resources are insufficient. The cause of this could be genuine load or DDoS, however.
  
-   Error rates—this measures the number of errors as a percentage of total calls, usually classifying error types under category headings. Errors may represent an overloaded system if the API is unresponsive, or a security issue, if the errors are authorization/access denied types.
  
-   Unauthorized and suspicious endpoints—connections to the API can be managed in the same sort of way as remote access. The client endpoint initiating the connection can be restricted using an ACL and the endpoint's IP address monitored for geographic location.
  

**Instance Awareness**  
As with on-premises virtualization, it is important to manage instances (virtual machines and containers) to avoid sprawl, where undocumented instances are launched and left unmanaged. As well as restricting rights to launch instances, you should configure logging and monitoring to track usage.