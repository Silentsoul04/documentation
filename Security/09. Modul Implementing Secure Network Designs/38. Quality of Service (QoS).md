# Quality of Service (QoS)

#### QUALITY OF SERVICE (QOS)

Most network appliances process packets on a best effort and first in, first out (FIFO) basis. **Quality of Service (QoS)** is a framework for prioritizing traffic based on its characteristics. It is primarily used to support voice and video applications that require a minimum level of bandwidth and are sensitive to latency and jitter. **Latency** is the time it takes for a transmission to reach the recipient, measured in milliseconds (ms). **Jitter** is defined as being a variation in the delay, or an inconsistent rate of packet delivery. FIFO-based delivery makes it more likely that other applications sharing the same network will cause loss of bandwidth and increase latency and jitter for a real-time service.

Implementing QoS is a complex project, as there are many different ways to do it, and many different protocols and appliances involved. In overview, a QoS implementation could work as follows:

1.  The organization performs application discovery to identify bandwidth, latency, and jitter thresholds of the protocols in use and determine their relative priority. The applications are then mapped to standard class of service (CoS) codes at layer 2 and layer 3. These codes are configured across the range of hosts and intermediate systems that handle QoS traffic.
    
2.  A QoS-compatible endpoint device or application uses the **DiffServ** field in the IP header (layer 3) and adds an 802.1p field to the Ethernet header (layer 2) to indicate that the packet should be treated as priority (traffic marking). It transmits the frame to the switch.
    
3.  If the switch supports QoS, it uses the 802.1p header to prioritize the frame. Note that it can only do this by holding a queue of outgoing traffic and delaying non-priority frames. If the queue is full, a traffic policing policy must state whether non-priority frames should be dropped, or whether the queue should be cleared at the expense of reducing QoS.
    
4.  A similar process occurs at routers and load balancers on the network edge, though they can inspect the DiffServ IP packet header, rather than having to rely on the more limited 802.1p header. Note that prioritization always takes place on the outbound interface, with low priority traffic being held in a queue.
    

> _There are many variations on this process. Modern layer 3 switches can inspect Differentiated Services Code Point (DSCP) values, rather than relying on 802.1p tagging, for instance. QoS may need to take place over wireless networks, which use a different tagging mechanism. There is also a wholly different approach to QoS called IntServ. This uses the Resource Reservation Protocol (RSVP) to negotiate a link with the performance characteristics required by the application or policy._

QoS marking introduces the potential for DoS attacks. If a threat actor can craft packets that are treated as high priority and send them at a high rate, the network can be overwhelmed. Part of QoS involves identifying trust boundaries to establish a legitimate authority for marking traffic. You should also ensure that there is always sufficient bandwidth for security-critical monitoring data and network management/configuration traffic.

> _For more information, consider these case studies and design overviews from Microsoft (_docs.microsoft.com/en-us/skypeforbusiness/optimizing-your-network/expressroute-and-qos-in-skype-for-business-online) and Cisco (cisco.com/c/en/us/td/docs/solutions/Enterprise/WAN\_and\_MAN/QoS\_SRND/QoS-SRND-Book/QoSIntro.html_)._